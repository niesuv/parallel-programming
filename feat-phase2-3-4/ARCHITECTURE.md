# CIFAR-10 Autoencoder + SVM Classification Pipeline

> **Project:** Phase 2, 3, 4 - Parallel Programming Final Project  
> **Goal:** Train autoencoder on CIFAR-10, extract features, classify with SVM

---

## ğŸ“‚ Project Structure

```
feat-phase2-3-4/
â”œâ”€â”€ include/                    # Header files
â”‚   â”œâ”€â”€ layer.h                 # CPU tensor & layer definitions
â”‚   â”œâ”€â”€ autoencoder.h           # CPU Autoencoder class
â”‚   â”œâ”€â”€ gpu_layer.h             # GPU tensor & layer definitions
â”‚   â”œâ”€â”€ gpu_autoencoder.h       # GPU Autoencoder class
â”‚   â”œâ”€â”€ cuda_utils.h            # CUDA error checking macros
â”‚   â”œâ”€â”€ dataset.h               # CIFAR-10 dataset loader
â”‚   â””â”€â”€ svm_wrapper.h           # SVM classifier (ThunderSVM/LIBSVM)
â”‚
â”œâ”€â”€ src/                        # Source implementations
â”‚   â”œâ”€â”€ main.cpp                # Entry: CPU training
â”‚   â”œâ”€â”€ main_gpu.cu             # Entry: GPU training + SVM pipeline
â”‚   â”œâ”€â”€ autoencoder.cpp         # CPU Autoencoder forward/backward
â”‚   â”œâ”€â”€ gpu_autoencoder.cu      # GPU Autoencoder forward/backward/encode
â”‚   â”œâ”€â”€ layers_cpu.cpp          # CPU layer implementations
â”‚   â”œâ”€â”€ layers_gpu.cu           # GPU layers (naive CUDA)
â”‚   â”œâ”€â”€ layers_gpu_opt.cu       # GPU layers (optimized CUDA)
â”‚   â”œâ”€â”€ dataset.cpp             # CIFAR-10 binary file loader
â”‚   â”œâ”€â”€ svm_wrapper.cpp         # SVM wrapper implementations
â”‚   â””â”€â”€ verify_gpu.cu           # GPU correctness verification
â”‚
â””â”€â”€ external/thundersvm/        # GPU-accelerated SVM (submodule)
```

---

## ğŸ—ï¸ Autoencoder Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ENCODER                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input:  [N, 3, 32, 32]   â† RGB CIFAR-10 images                 â”‚
â”‚     â†“                                                            â”‚
â”‚  Conv2D(3â†’256, 3Ã—3, pad=1) + ReLU                               â”‚
â”‚     â†“ [N, 256, 32, 32]                                          â”‚
â”‚  MaxPool2D(2Ã—2)                                                  â”‚
â”‚     â†“ [N, 256, 16, 16]                                          â”‚
â”‚  Conv2D(256â†’128, 3Ã—3, pad=1) + ReLU                             â”‚
â”‚     â†“ [N, 128, 16, 16]                                          â”‚
â”‚  MaxPool2D(2Ã—2)                                                  â”‚
â”‚     â†“ [N, 128, 8, 8]   â† LATENT SPACE (8192 features)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      DECODER                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conv2D(128â†’128, 3Ã—3, pad=1) + ReLU                             â”‚
â”‚     â†“ [N, 128, 8, 8]                                            â”‚
â”‚  UpSample2D(scale=2)                                            â”‚
â”‚     â†“ [N, 128, 16, 16]                                          â”‚
â”‚  Conv2D(128â†’256, 3Ã—3, pad=1) + ReLU                             â”‚
â”‚     â†“ [N, 256, 16, 16]                                          â”‚
â”‚  UpSample2D(scale=2)                                            â”‚
â”‚     â†“ [N, 256, 32, 32]                                          â”‚
â”‚  Conv2D(256â†’3, 3Ã—3, pad=1)                                      â”‚
â”‚     â†“                                                            â”‚
â”‚  Output: [N, 3, 32, 32]  â† Reconstructed images                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Pipeline Flows

### Pipeline 1: CPU Training (`cpu_train`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load CIFAR-10    â”‚
â”‚ (50K train, 10K  â”‚
â”‚  test images)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Init CPU         â”‚
â”‚ Autoencoder      â”‚
â”‚ (random weights) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each epoch   â”‚â”€â”€â”€â”€â†’â”‚ For each batch    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â€¢ Forward pass   â”‚
         â”‚               â”‚  â€¢ MSE loss       â”‚
         â”‚               â”‚  â€¢ Backward pass  â”‚
         â”‚               â”‚  â€¢ Update weights â”‚
         â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Save weights to  â”‚
â”‚ binary file      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Build:** `make cpu_train` or CMake target `cpu_train`  
**Run:** `./cpu_train data/ 5 32 0.001`

---

### Pipeline 2: GPU Training (`gpu_train` / `gpu_train_opt`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INITIALIZATION                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check CUDA GPU   â”‚â”€â”€â”€â”€â†’â”‚ Load CIFAR-10    â”‚
â”‚ Tesla T4, etc.   â”‚     â”‚ dataset          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Init GPU         â”‚
                         â”‚ Autoencoder      â”‚
                         â”‚ + Load weights?  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TRAINING LOOP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each epoch   â”‚â”€â”€â”€â”€â†’â”‚ For each batch:                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  1. Allocate pinned host memory       â”‚
         â”‚               â”‚  2. cudaMemcpyAsync â†’ GPU              â”‚
         â”‚               â”‚  3. Forward (Conv+ReLU+Pool+Up)        â”‚
         â”‚               â”‚  4. MSE Loss via parallel reduction    â”‚
         â”‚               â”‚  5. Backward (gradient descent)        â”‚
         â”‚               â”‚  6. cudaStreamSynchronize              â”‚
         â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Save weights     â”‚
â”‚ (binary format)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[If WITH_SVM defined, continue to Pipeline 3]
```

**Build:** `./build.sh` (CMake)  
**Run:** `./build/bin/full_pipeline --epochs 10 --data ./data/cifar-10-batches-bin`

**Optimizations (Phase 3 vs Phase 2):**
- Memory coalescing in Conv2D
- Warp shuffle for reduction
- Tiled shared memory
- Loop unrolling for 3Ã—3 kernels
- Pinned host memory for async transfers

---

### Pipeline 3: Feature Extraction + SVM Classification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FEATURE EXTRACTION                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load trained     â”‚
â”‚ autoencoder      â”‚
â”‚ weights          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each image   â”‚â”€â”€â”€â”€â†’â”‚ encode() function:                    â”‚
â”‚ (train + test)   â”‚     â”‚  1. Copy image â†’ GPU                  â”‚
â”‚                  â”‚     â”‚  2. Conv1 + ReLU â†’ Pool1              â”‚
â”‚                  â”‚     â”‚  3. Conv2 + ReLU â†’ Pool2              â”‚
â”‚                  â”‚     â”‚  4. Output: 128Ã—8Ã—8 = 8192 features   â”‚
â”‚                  â”‚     â”‚  5. cudaStreamSynchronize             â”‚
â”‚                  â”‚     â”‚  6. Copy features â†’ CPU               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FEATURE NORMALIZATION                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Standardize:     â”‚
â”‚ mean = 0         â”‚
â”‚ std = 1          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SVM CLASSIFICATION                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Train SVM on     â”‚â”€â”€â”€â”€â†’â”‚ Predict test     â”‚
â”‚ 50K train        â”‚     â”‚ features         â”‚
â”‚ features+labels  â”‚     â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Compute          â”‚
                         â”‚ Accuracy         â”‚
                         â”‚ (expected >40%)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Run (SVM-only mode):**
```bash
./build/bin/full_pipeline --load-weights autoencoder_gpu.weights --svm-only --data ./data/cifar-10-batches-bin
```

---

## âš™ï¸ Build Commands

### CMake (Recommended)
```bash
./build.sh               # Build all targets
./build.sh --clean       # Clean build
```

### Executables
| Binary | Description |
|--------|-------------|
| `gpu_train` | Train autoencoder only (no SVM) |
| `full_pipeline` | Train autoencoder + SVM classification |
| `thundersvm-train` | Standalone ThunderSVM training tool |

---

## ğŸ”§ Key Configuration Flags

| Flag | Description |
|------|-------------|
| `USE_OPTIMIZED_KERNELS` | Enable Phase 3 CUDA optimizations |
| `WITH_SVM` | Enable SVM classification pipeline |
| `WITH_THUNDERSVM` | Use GPU-accelerated ThunderSVM |
| `WITH_LIBSVM` | Fallback to CPU LIBSVM |

---

## ğŸ“Š Layer Implementations Summary

| Layer | CPU File | GPU Naive | GPU Optimized |
|-------|----------|-----------|---------------|
| Conv2D | `layers_cpu.cpp` | `layers_gpu.cu` | `layers_gpu_opt.cu` (tiled + coalesced) |
| ReLU | `layers_cpu.cpp` | `layers_gpu.cu` | `layers_gpu_opt.cu` (fused with Conv) |
| MaxPool2D | `layers_cpu.cpp` | `layers_gpu.cu` | `layers_gpu_opt.cu` (2D blocks) |
| UpSample2D | `layers_cpu.cpp` | `layers_gpu.cu` | `layers_gpu_opt.cu` |
| MSE Loss | `layers_cpu.cpp` | `layers_gpu.cu` | `layers_gpu_opt.cu` (warp shuffle) |

---

## ğŸ“ Weight File Format

Binary format with magic number verification:
```
[4 bytes] Magic: 0x48414557 ("WEAH")
[4 bytes] Version: 1
[4 bytes] Num layers: 5

For each conv layer:
  [4 bytes] in_channels
  [4 bytes] out_channels
  [4 bytes] kernel_size
  [4 bytes] weights_count
  [N floats] weights data
  [4 bytes] bias_count
  [M floats] bias data
```
