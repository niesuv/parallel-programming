{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Fullname: qtf\n",
        "\n",
        "Student ID: 69"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: CUDA Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "**To compile your file, you can use this command:** \\\n",
        "`nvcc filename.cu -o execute_filename` \\\n",
        "***You can use Vietnamese to anwser the questions***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "You can add/delete cells as you see fit. Just don't delete the cells with the Teacher's words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIttr7kEJ5GW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0silsCJ5GW"
      },
      "source": [
        "Below is the command to install `Nsight system` on Colab. You just need to run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y0VUsRvJJ5GX",
        "outputId": "089b1df2-1e3d-43a4-8935-2686021fb45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cuda-nsight-systems-12-2 is already the newest version (12.2.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Here is the command to install Nsight system on Colab. You just need to run the cell.\n",
        "!apt-get update\n",
        "!apt-get install -y cuda-nsight-systems-12-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRHcSuJTJ5GZ"
      },
      "source": [
        "- The above installation will be remove when colab restart its runtime. It should be fine for this homework because we don't use Nsight system that much.\n",
        "- But if you want to persistent install Nsight system, you mount space from your Google Drive to your Colab VM. Read [Here](https://stackoverflow.com/questions/76784746/how-to-use-nsys-in-google-colab) for guidelines how to do thhis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO69Wi6cJ5GZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj7K23NbKE-n",
        "outputId": "021b634a-9964-46b1-e47b-5fe4ac6655d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f\"GPU compute capability: {major}.{minor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "aK4h6sonKFqn",
        "outputId": "30ca2fff-9b94-4b37-cab0-076c95762105"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-516c9802-e351-453e-a416-68d18d767744\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-516c9802-e351-453e-a416-68d18d767744\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving HW3_P1.cu to HW3_P1.cu\n",
            "Saving HW3_P2.cu to HW3_P2.cu\n",
            "Saving in.pnm to in.pnm\n",
            "Saving test_1x1_pixel.pnm to test_1x1_pixel.pnm\n",
            "Saving test_1x50_row.pnm to test_1x50_row.pnm\n",
            "Saving test_250x250.pnm to test_250x250.pnm\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbFLx1i4JxIE"
      },
      "source": [
        "## Exercises 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-do6kaBWlj-"
      },
      "source": [
        "### Thử nghiệm với ảnh mẫu (512x512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aZNqZuECjNso"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3_P1.cu -o HW3_P1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVFUj14OYUyy",
        "outputId": "3bd383eb-2f6f-41ac-b55a-1adae27ea5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15828320256 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.765792 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.341760 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.268256 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P1 in.pnm out.pnm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjz2eE_5QLHH"
      },
      "source": [
        "**Nhận xét**\n",
        "\n",
        "| Version | Logic | Pros | Kernel time |\n",
        "|-----------|----------|-----------|-------------|\n",
        "| Kernel 1 | Đọc trực tiếp Global Memory | Dễ hiểu, không cần tile | 0.766 ms |\n",
        "| Kernel 2 | Shared Memory tile | Giảm số lần truy cập GMEM | 0.342 ms |\n",
        "| Kernel 3 | Shared + Constant Memory | Broadcast hệ số filter, tái sử dụng tile | 0.268 ms |\n",
        "\n",
        "- **Shared Memory** giảm thời gian vì mỗi block nạp tile + halo lên SMEM một lần rồi tái dùng cho 81 phép nhân (filterWidth=9), thay vì mỗi thread tự đọc 81 lần từ GMEM; chi phí `__syncthreads()` nhỏ hơn rất nhiều so với lượng truy cập bộ nhớ tiết kiệm được.\n",
        "- **Constant Memory** ở kernel 3 giúp warp nhận hệ số filter qua broadcast một giao dịch, loại bỏ thêm 32 lượt đọc GMEM cho mỗi hệ số, nên tiếp tục rút ~20% thời gian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08tJ2wmZWqMe"
      },
      "source": [
        "### Thử nghiệm đặc biệt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w--T9tabWYiu",
        "outputId": "5bd429e2-fd9e-4470-c381-851dedc4263d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15828320256 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 1 x 1\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 1x1\n",
            "Kernel time: 0.301184 ms\n",
            "Error: 0.000000\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 1x1\n",
            "Kernel time: 0.065568 ms\n",
            "Error: 0.000000\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 1x1\n",
            "Kernel time: 0.060864 ms\n",
            "Error: 0.000000\n",
            "\n",
            "Kernel 4, block size 1x1, grid size 1x1\n",
            "Kernel time: 0.052704 ms\n",
            "Error: 0.666667\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P1 test_1x1_pixel.pnm out_test_1x1_pixel.pnm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiX-ItqzWv2v",
        "outputId": "a1bbc55a-eee5-4dc5-c5de-e083b23f3cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15828320256 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 50 x 1\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 4x1\n",
            "Kernel time: 0.279584 ms\n",
            "Error: 0.006667\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 4x1\n",
            "Kernel time: 0.083872 ms\n",
            "Error: 0.006667\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 4x1\n",
            "Kernel time: 0.059968 ms\n",
            "Error: 0.006667\n",
            "\n",
            "Kernel 4, block size 50x1, grid size 1x1\n",
            "Kernel time: 0.042208 ms\n",
            "Error: 0.060000\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P1 test_1x50_row.pnm out_test_1x50_row.pnm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ralRHlW44e",
        "outputId": "8258b141-fb97-4e32-aff6-45ee9a6f5548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15828320256 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 250 x 250\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 16x16\n",
            "Kernel time: 0.385312 ms\n",
            "Error: 0.000235\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 16x16\n",
            "Kernel time: 0.131904 ms\n",
            "Error: 0.000235\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 16x16\n",
            "Kernel time: 0.114688 ms\n",
            "Error: 0.000235\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P1 test_250x250.pnm out_test_250x250.pnm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8YYARDap1xb"
      },
      "source": [
        "**Nhận xét**\n",
        "\n",
        "| Ảnh đầu vào      | Kernel 1 (GMEM-only) | Kernel 2 (Tile SMEM) | Kernel 3 (SMEM + CMEM) | Kernel 4 (Line-SMEM) |\n",
        "|------------------|----------------------|----------------------|------------------------|----------------------|\n",
        "| `test_1x1_pixel` | 0.301 ms / 0.00000   | 0.066 ms / 0.00000   | 0.061 ms / 0.00000     | 0.053 ms / 0.66667   |\n",
        "| `test_1x50_row`  | 0.280 ms / 0.00667   | 0.084 ms / 0.00667   | 0.060 ms / 0.00667     | 0.042 ms / 0.06000   |\n",
        "| `test_250x250`   | 0.385 ms / 0.00024   | 0.132 ms / 0.00024   | 0.115 ms / 0.00024     | —                    |\n",
        "\n",
        "- Kernel 4 chuyên cho ảnh 1D nên nhanh nhất, nhưng sai số lớn (thấy rõ ở `test_1x1_pixel`, `test_1x50_row`). Khi ảnh vuông, Kernel 3 vẫn là lựa chọn cân bằng giữa tốc độ và độ chính xác."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "## Exercises 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QCm1dUPpUtj-"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3_P2.cu -o HW3_P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DojS2E4VdGn",
        "outputId": "f40b09e5-9d1e-4455-fa66-9425edcaf7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 8\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 128.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 25.53 ms\n",
            "Breakdown (avg per vector) -> H2D: 1.41 ms (44.6%), Kernels: 0.46 ms (14.5%), D2H: 1.29 ms (40.9%)\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 16.97 ms\n",
            "Breakdown (avg per vector) -> H2D: 7.42 ms (69.2%), Kernels: 0.81 ms (7.5%), D2H: 2.49 ms (23.2%)\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 15.43 ms\n",
            "Breakdown (avg per vector) -> H2D: 7.46 ms (76.9%), Kernels: 0.47 ms (4.8%), D2H: 1.77 ms (18.2%)\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     25.53 ms\n",
            "Breadth-First:  16.97 ms  (1.50x speedup)\n",
            "Depth-First:    15.43 ms  (1.65x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.10x\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crf3C9cIVf73",
        "outputId": "b9486b90-7b57-4102-b04a-a1458a3cbe08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 16\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 256.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 50.25 ms\n",
            "Breakdown (avg per vector) -> H2D: 1.38 ms (44.2%), Kernels: 0.45 ms (14.4%), D2H: 1.29 ms (41.4%)\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 35.45 ms\n",
            "Breakdown (avg per vector) -> H2D: 14.84 ms (74.1%), Kernels: 0.95 ms (4.8%), D2H: 4.25 ms (21.2%)\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 30.66 ms\n",
            "Breakdown (avg per vector) -> H2D: 8.32 ms (77.9%), Kernels: 0.46 ms (4.3%), D2H: 1.91 ms (17.8%)\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     50.25 ms\n",
            "Breadth-First:  35.45 ms  (1.42x speedup)\n",
            "Depth-First:    30.66 ms  (1.64x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.16x\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P2 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqwwV-aYViXW",
        "outputId": "c66bcf37-aee7-492e-8705-65fb5e32da8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 32\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 512.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 100.56 ms\n",
            "Breakdown (avg per vector) -> H2D: 1.38 ms (44.3%), Kernels: 0.44 ms (14.3%), D2H: 1.29 ms (41.4%)\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 72.80 ms\n",
            "Breakdown (avg per vector) -> H2D: 29.96 ms (76.9%), Kernels: 1.19 ms (3.1%), D2H: 7.83 ms (20.1%)\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 62.12 ms\n",
            "Breakdown (avg per vector) -> H2D: 8.90 ms (78.5%), Kernels: 0.46 ms (4.0%), D2H: 1.99 ms (17.5%)\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     100.56 ms\n",
            "Breadth-First:  72.80 ms  (1.38x speedup)\n",
            "Depth-First:    62.12 ms  (1.62x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.17x\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P2 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "czSfaWQVJ5Ga"
      },
      "outputs": [],
      "source": [
        "# Generate report with nsight system\n",
        "!nsys profile ./HW3_P2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf9ygDpPfiB-"
      },
      "source": [
        "### Report\n",
        "\n",
        "#### Question 1: Performance Analysis\n",
        "**Tại sao depth-first nhanh hơn breadth-first?**\n",
        "\n",
        "**Depth-first** pipeline mỗi stream thực thi tuần tự đầy đủ: H2D → Scale → Add → Square → D2H. Điều này cho phép:\n",
        "- **Overlapping tối đa**: Khi stream 1 đang compute (kernels), stream 2 có thể H2D, stream 3 D2H → copy engines và SM hoạt động song song liên tục.\n",
        "- **Giảm idle time**: GPU không phải chờ đợi giữa các phase như breadth-first.\n",
        "\n",
        "**Breadth-first** thực thi theo batch từng loại operation (tất cả H2D → tất cả kernels → tất cả D2H), dẫn đến:\n",
        "- Copy engines rảnh trong phase compute, SM rảnh trong phase transfer.\n",
        "- Overhead đồng bộ giữa các phase.\n",
        "\n",
        "**Kết quả thực nghiệm**: Với 16 vectors, depth-first (30.66 ms) nhanh hơn breadth-first (35.45 ms) ~16%.\n",
        "\n",
        "#### Question 2: Scalability\n",
        "| Vectors | Sequential (ms) | Breadth-First (ms) | Depth-First (ms) | Speedup BF | Speedup DF |\n",
        "|---------|-----------------|--------------------|-----------------|-----------:|----------:|\n",
        "| 8       | 25.53           | 16.97              | 15.43           | 1.50×      | 1.65×     |\n",
        "| 16      | 50.25           | 35.45              | 30.66           | 1.42×      | 1.64×     |\n",
        "| 32      | 100.56          | 72.80              | 62.12           | 1.38×      | 1.62×     |\n",
        "\n",
        "**Nhận xét**:\n",
        "- Thời gian tăng gần tuyến tính theo số vectors do tổng data tăng (128 MB → 512 MB).\n",
        "- Depth-first duy trì lợi thế 15-17% so với breadth-first nhờ pipeline hiệu quả hơn.\n",
        "- Speedup giảm dần khi scale up do GPU đạt gần saturation bandwidth.\n",
        "\n",
        "![](output.png)\n",
        "\n",
        "![](output2.png)\n",
        "\n",
        "#### Question 3: Memory Transfer vs Computation\n",
        "**8 vectors (Sequential)**:\n",
        "- H2D: 1.41 ms (44.6%)\n",
        "- Kernels: 0.46 ms (14.5%)\n",
        "- D2H: 1.29 ms (40.9%)\n",
        "- **→ 85% thời gian là memory transfer**, compute chỉ chiếm 15%.\n",
        "\n",
        "**8 vectors (Breadth-First)**: \n",
        "- Streams giúp overlap, giảm total time từ 25.53 ms → 16.97 ms (1.50× speedup).\n",
        "- Transfer vẫn chiếm ~92% (H2D 69.2% + D2H 23.2%).\n",
        "\n",
        "**32 vectors (Depth-First)**:\n",
        "- H2D: 78.5%, Kernels: 4.0%, D2H: 17.5%\n",
        "- Depth-first che giấu compute bằng cách overlap với transfer của streams khác.\n",
        "- **Bottleneck chính**: PCIe bandwidth, không phải SM throughput.\n",
        "\n",
        "**Kết luận**: Workload này memory-bound. Streams giúp tận dụng tối đa băng thông nhưng không thể vượt qua giới hạn vật lý của PCIe.\n",
        "\n",
        "#### Question 4\n",
        "\n",
        "![Nsight](NVIDIA_Nsight_Systems.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
