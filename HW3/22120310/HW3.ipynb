{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Fullname: Lê Hữu Sang\n",
        "\n",
        "Student ID: 22120310"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: CUDA Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "**To compile your file, you can use this command:** \\\n",
        "`nvcc filename.cu -o execute_filename` \\\n",
        "***You can use Vietnamese to anwser the questions***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "You can add/delete cells as you see fit. Just don't delete the cells with the Teacher's words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsZMUs2IdK0d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7gwcipdK0e"
      },
      "source": [
        "Below is the command to install `Nsight system` on Colab. You just need to run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16FzUeAqdK0f",
        "outputId": "10f76480-0df6-4d63-840e-fa7ef1839d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connecting to security.\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [C\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cuda-nsight-systems-12-2 is already the newest version (12.2.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Here is the command to install Nsight system on Colab. You just need to run the cell.\n",
        "!apt-get update\n",
        "!apt-get install -y cuda-nsight-systems-12-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfcrC1gHdK0j"
      },
      "source": [
        "- The above installation will be remove when colab restart its runtime. It should be fine for this homework because we don't use Nsight system that much.\n",
        "- But if you want to persistent install Nsight system, you mount space from your Google Drive to your Colab VM. Read [Here](https://stackoverflow.com/questions/76784746/how-to-use-nsys-in-google-colab) for guidelines how to do thhis."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f\"GPU compute capability: {major}.{minor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPKobyWce4LY",
        "outputId": "6f329ec8-6361-4ab8-daa2-b6f559b21702"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_pnm_side_by_side(file_list, titles=None, figsize=(15, 5)):\n",
        "    n = len(file_list)\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i, path in enumerate(file_list):\n",
        "        try:\n",
        "            img = Image.open(path)\n",
        "        except Exception as e:\n",
        "            print(f\"Cannot open {path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        cmap = \"gray\" if img.mode == \"L\" else None\n",
        "        plt.imshow(img, cmap=cmap)\n",
        "        title = titles[i] if titles and i < len(titles) else path\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "6zFSNptAfUBv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6qxyNITdK0j"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbFLx1i4JxIE"
      },
      "source": [
        "## Exercises 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aZNqZuECjNso"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3_P1.cu -o HW3_P1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NVFUj14OYUyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c44a70-8eb4-4ad5-c055-526cbf7fd499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15828320256 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.716832 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.342016 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.278496 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ],
      "source": [
        "!./HW3_P1 in.pnm out.pnm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nhận xét chi tiết\n",
        "\n",
        "### 1) Kernel 1 – đọc dữ liệu thô từ Global Memory\n",
        "Phiên bản này mỗi thread phải tự lấy toàn bộ 81 giá trị từ global memory để thực hiện convolution.  \n",
        "Dù GPU có cache hỗ trợ, lượng truy cập vẫn rất lớn, và **bandwidth DRAM trở thành giới hạn chính**.  \n",
        "**Ưu điểm:** dễ cài đặt.\n",
        "\n",
        "---\n",
        "\n",
        "### 2) Kernel 2 – dùng Shared Memory để chứa vùng tile\n",
        "Ở phiên bản này, cả block hợp tác nạp toàn bộ ô dữ liệu đầu vào (bao gồm cả biên) lên shared memory **một lần duy nhất**.  \n",
        "Phần dữ liệu này sau đó được **tái sử dụng cho tất cả 256 pixels output** trong cùng block.\n",
        "\n",
        "**Ưu điểm:**\n",
        "\n",
        "- Số lần đọc từ DRAM giảm xuống chỉ còn một phần nhỏ so với kernel 1  \n",
        "- Truy cập shared memory nhanh hơn nhiều vì độ trễ thấp và nằm ngay trong SM  \n",
        "- Chi phí đồng bộ (`__syncthreads()`) chỉ một vài lần và nhỏ hơn rất nhiều so với lượng dữ liệu tiết kiệm được  \n",
        "\n",
        "**Kết quả thực tế:** thời gian giảm gần **2×**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3) Kernel 3 – combination của Shared Memory + Constant Memory\n",
        "Phiên bản cuối vừa tận dụng tile trong shared memory, vừa đưa toàn bộ **filter** vào constant memory.\n",
        "\n",
        "**Ưu điểm:**\n",
        "\n",
        "- Bộ lọc kích thước nhỏ, phù hợp với constant memory  \n",
        "- Mỗi bước tính, toàn bộ thread trong warp đọc cùng một hệ số  \n",
        "- GPU có cơ chế **broadcast** cho cả warp chỉ trong một giao dịch  \n",
        "- Hiệu quả cache gần như tối đa (hit rate rất cao)\n",
        "\n",
        "**Kết quả:** phần đọc hệ số filter từ global memory gần như bị loại bỏ hoàn toàn, thời gian tiếp tục giảm thêm khoảng **20–25%** so với kernel 2.\n"
      ],
      "metadata": {
        "id": "_MttjlKphzBZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "## Exercises 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3_P2.cu -o HW3_P2"
      ],
      "metadata": {
        "id": "y5lnMbIVkU9d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3_P2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QabLoYzZvJKH",
        "outputId": "4476099b-1cb0-468d-a82f-b06d442105f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 8\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 128.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 25.45 ms\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 15.51 ms\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 15.60 ms\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     25.45 ms\n",
            "Breadth-First:  15.51 ms  (1.64x speedup)\n",
            "Depth-First:    15.60 ms  (1.63x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 0.99x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3_P2 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojy75wVBvMDk",
        "outputId": "c0bbf35e-e287-4c7d-a14f-74cca0d2e31d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 16\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 256.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 50.04 ms\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 32.62 ms\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 30.44 ms\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     50.04 ms\n",
            "Breadth-First:  32.62 ms  (1.53x speedup)\n",
            "Depth-First:    30.44 ms  (1.64x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.07x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "neAYjZfRzDms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3_P2 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXA72nduvRW3",
        "outputId": "a976cf9e-b52a-47b6-f56a-eccd0767573a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 32\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 512.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 100.63 ms\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 68.56 ms\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 61.83 ms\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     100.63 ms\n",
            "Breadth-First:  68.56 ms  (1.47x speedup)\n",
            "Depth-First:    61.83 ms  (1.63x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.11x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOrWK0ihdK0n",
        "outputId": "3b7093f1-c58d-4ad2-de38-f57516a121b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║  VECTOR OPERATIONS PIPELINE EXERCISE   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Configuration:\n",
            "  Number of vectors: 8\n",
            "  Elements per vector: 4194304 (16.00 MB)\n",
            "  Total data: 128.00 MB\n",
            "\n",
            "GPU: Tesla T4\n",
            "Concurrent kernels supported: Yes\n",
            "Number of copy engines: 3\n",
            "\n",
            "\n",
            "=== SEQUENTIAL (NO STREAMS) ===\n",
            "Time: 25.64 ms\n",
            "\n",
            "=== BREADTH-FIRST PIPELINE ===\n",
            "Time: 15.54 ms\n",
            "\n",
            "=== DEPTH-FIRST PIPELINE ===\n",
            "Time: 15.48 ms\n",
            "\n",
            "=== VERIFICATION ===\n",
            "✓ All results match!\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         PERFORMANCE SUMMARY            ║\n",
            "╚════════════════════════════════════════╝\n",
            "Sequential:     25.64 ms\n",
            "Breadth-First:  15.54 ms  (1.65x speedup)\n",
            "Depth-First:    15.48 ms  (1.66x speedup)\n",
            "\n",
            "Depth-First vs Breadth-First: 1.00x\n",
            "Generating '/tmp/nsys-report-9137.qdstrm'\n",
            "[1/1] [========================100%] report2.nsys-rep\n",
            "Generated:\n",
            "    /content/report2.nsys-rep\n"
          ]
        }
      ],
      "source": [
        "# Generate report with nsight system\n",
        "!nsys profile ./HW3_P2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phần B — Phân tích hiệu năng"
      ],
      "metadata": {
        "id": "f-5AMoaiyb9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Performance Analysis Why is depth-first faster than breadth-first?\n",
        "\n",
        "**Depth-first (DF):**\n",
        "- Với DF, mỗi vector được xử lý toàn bộ pipeline **(H2D → kernels → D2H)** trên **một stream**.\n",
        "- Nhờ vậy, giữa các stream có thể **overlap copy–compute** (khi dùng pinned memory và GPU có nhiều copy engines).\n",
        "- Khi stream A chạy kernel, stream B đang copy dữ liệu → tận dụng tài nguyên tốt hơn.\n",
        "\n",
        "**Breadth-first (BF):**\n",
        "- BF thực hiện cùng một pha cho tất cả vector (copy hết H2D, rồi chạy tất cả kernel, rồi copy hết D2H).\n",
        "- Tạo ra **burst load** lên PCIe và hàng đợi kernel.\n",
        "- Khó đạt overlap copy–compute vì toàn bộ pipeline bị dồn theo chiều ngang.\n",
        "\n",
        "**Kết luận:**\n",
        "- DF thường nhanh hơn BF nhờ tránh nghẽn tài nguyên, phân bố đều công việc và tạo nhiều cơ hội overlap copy–compute.\n"
      ],
      "metadata": {
        "id": "zXIjfc-4yj8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Scalability\n",
        "+ What happens if you increase the number of vectors to 16? 32?\n",
        "+ Students should experiment and plot results"
      ],
      "metadata": {
        "id": "jSlx6UXlytNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Kết quả với 16 vectors**\n",
        "\n",
        "| Phương pháp      | Thời gian (ms) | Speedup so với Sequential |\n",
        "|------------------|----------------|----------------------------|\n",
        "| Sequential       | 51.06 ms       | 1.00×                      |\n",
        "| Breadth-First    | 33.23 ms       | 1.54×                      |\n",
        "| Depth-First      | 31.07 ms       | 1.64×                      |\n",
        "\n",
        "**Nhận xét:**  \n",
        "Khi tăng lên 16 vectors, cả hai mô hình pipeline đều nhanh hơn rõ rệt so với sequential. Depth-First tiếp tục nhanh nhất vì khả năng overlap giữa H2D, compute và D2H tốt hơn. Breadth-First cũng cải thiện nhưng vẫn chậm hơn DF một chút do copy theo “đợt lớn” dễ làm nghẽn băng thông.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Kết quả với 32 vectors**\n",
        "\n",
        "| Phương pháp      | Thời gian (ms) | Speedup so với Sequential |\n",
        "|------------------|----------------|----------------------------|\n",
        "| Sequential       | 100.11 ms      | 1.00×                      |\n",
        "| Breadth-First    | 68.56 ms       | 1.46×                      |\n",
        "| Depth-First      | 61.76 ms       | 1.62×                      |\n",
        "\n",
        "**Nhận xét:**  \n",
        "Với 32 vectors, thời gian chạy của sequential tăng gần như đúng tuyến tính.  \n",
        "Hai pipeline vẫn nhanh hơn nhiều, nhưng hiệu suất bắt đầu giảm vì băng thông PCIe và tài nguyên copy-engine bị chia sẻ cho quá nhiều stream. Dù vậy, Depth-First vẫn giữ được tốc độ tốt nhất, vượt Breadth-First khoảng 1.11×.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Kết luận**\n",
        "\n",
        "- Khi số vector tăng, tổng thời gian chạy tăng theo, nhưng pipeline giúp che bớt thời gian copy và tăng khả năng overlap.\n",
        "- **Depth-First mở rộng tốt nhất**, giữ được mức overlap cao giữa copy và tính toán.\n",
        "- **Breadth-First mở rộng vừa phải**, nhưng kém hiệu quả hơn khi số vectors lớn do tắc nghẽn băng thông.\n",
        "- **Sequential tăng hoàn toàn tuyến tính**, không có overlap nên chậm nhất."
      ],
      "metadata": {
        "id": "QHZiPxbzzfq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Memory Transfer\n",
        "How much time is spent on memory transfers vs computation?\n",
        "Student can modift the code to get these time duration.\n",
        "For example: 30-40% transfer, 60-70% compute. Streams help overlap these components"
      ],
      "metadata": {
        "id": "N9W5pvtzztmY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}