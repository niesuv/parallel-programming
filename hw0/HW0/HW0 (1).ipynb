{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Lê Minh Quân\n",
        "\n",
        "MSSV: 22120291"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW0: Làm quen với CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bCkmnirl2xWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b66f2f-fd86-4784-d3f1-14b9f35fb37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkZaH7EE-ocN"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH9lSjFfr3Kw"
      },
      "source": [
        "## Câu 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NVFUj14OYUyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496b4c98-6a2e-4993-83c6-d879da7953b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing HW0_P1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile HW0_P1.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    printf(\"Number of CUDA devices: %d\\n\\n\", deviceCount);\n",
        "\n",
        "    for (int dev = 0; dev < deviceCount; ++dev) {\n",
        "        cudaDeviceProp prop;\n",
        "        cudaGetDeviceProperties(&prop, dev);\n",
        "\n",
        "        printf(\"=== Device %d ===\\n\", dev);\n",
        "        printf(\"GPU name: %s\\n\", prop.name);\n",
        "        printf(\"Compute capability: %d.%d\\n\", prop.major, prop.minor);\n",
        "        printf(\"Total global memory: %zu bytes\\n\", prop.totalGlobalMem);\n",
        "        printf(\"Shared memory per block: %zu bytes\\n\", prop.sharedMemPerBlock);\n",
        "        printf(\"Constant memory: %zu bytes\\n\", prop.totalConstMem);\n",
        "        printf(\"Max threads per block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "        printf(\"Max block dimensions: %d %d %d\\n\", prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);\n",
        "        printf(\"Max grid dimensions: %d %d %d\\n\", prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);\n",
        "        printf(\"Warp size: %d\\n\", prop.warpSize);\n",
        "        printf(\"===================\\n\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc HW0_P1.cu -o HW0_P1\n",
        "!./HW0_P1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcz780tuE46S",
        "outputId": "50ead279-6fb8-4736-c00d-0f2aeca836f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CUDA devices: 1\n",
            "\n",
            "=== Device 0 ===\n",
            "GPU name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Total global memory: 15828320256 bytes\n",
            "Shared memory per block: 49152 bytes\n",
            "Constant memory: 65536 bytes\n",
            "Max threads per block: 1024\n",
            "Max block dimensions: 1024 1024 64\n",
            "Max grid dimensions: 2147483647 65535 65535\n",
            "Warp size: 32\n",
            "===================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlycLWxberDO"
      },
      "source": [
        "## Câu 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile HW0_P2.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// ---------------- VERSION 1 ----------------\n",
        "// mỗi thread cộng 2 phần tử cách nhau blockDim.x\n",
        "__global__ void vecAdd_v1(const float *A, const float *B, float *C, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int idx2 = idx + blockDim.x;\n",
        "    if (idx < N)\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    if (idx2 < N)\n",
        "        C[idx2] = A[idx2] + B[idx2];\n",
        "}\n",
        "\n",
        "// ---------------- VERSION 2 ----------------\n",
        "// mỗi thread cộng 2 phần tử liên tiếp\n",
        "__global__ void vecAdd_v2(const float *A, const float *B, float *C, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x * 2;\n",
        "    if (idx < N)\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    if (idx + 1 < N)\n",
        "        C[idx + 1] = A[idx + 1] + B[idx + 1];\n",
        "}\n",
        "\n",
        "// ---------------- HOST ADD ----------------\n",
        "void vecAdd_host(const float *A, const float *B, float *C, int N) {\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "// ---------------- MAIN ----------------\n",
        "int main() {\n",
        "    int sizes[] = {64, 256, 1024, 4096, 16384, 65536, 262144, 1048576, 4194304, 16777216};\n",
        "    int num_sizes = sizeof(sizes) / sizeof(int);\n",
        "\n",
        "    printf(\"%-12s %-12s %-18s %-18s\\n\", \"VectorSize\", \"HostTime(ms)\", \"Device_v1(ms)\", \"Device_v2(ms)\");\n",
        "\n",
        "    for (int s = 0; s < num_sizes; ++s) {\n",
        "        int N = sizes[s];\n",
        "        size_t bytes = N * sizeof(float);\n",
        "\n",
        "        float *h_A = (float*)malloc(bytes);\n",
        "        float *h_B = (float*)malloc(bytes);\n",
        "        float *h_C = (float*)malloc(bytes);\n",
        "        float *d_A, *d_B, *d_C;\n",
        "        cudaMalloc(&d_A, bytes);\n",
        "        cudaMalloc(&d_B, bytes);\n",
        "        cudaMalloc(&d_C, bytes);\n",
        "\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            h_A[i] = i * 0.5f;\n",
        "            h_B[i] = i * 0.25f;\n",
        "        }\n",
        "\n",
        "        // ---- Host time ----\n",
        "        auto t1 = chrono::high_resolution_clock::now();\n",
        "        vecAdd_host(h_A, h_B, h_C, N);\n",
        "        auto t2 = chrono::high_resolution_clock::now();\n",
        "        double hostTime = chrono::duration<double, milli>(t2 - t1).count();\n",
        "\n",
        "        cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_B, h_B, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "        int grid_v1 = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "        int grid_v2 = (N + BLOCK_SIZE * 2 - 1) / (BLOCK_SIZE * 2);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        float time_v1, time_v2;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        // ---- Version 1 ----\n",
        "        cudaEventRecord(start);\n",
        "        vecAdd_v1<<<grid_v1, BLOCK_SIZE>>>(d_A, d_B, d_C, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        cudaEventElapsedTime(&time_v1, start, stop);\n",
        "\n",
        "        // ---- Version 2 ----\n",
        "        cudaEventRecord(start);\n",
        "        vecAdd_v2<<<grid_v2, BLOCK_SIZE>>>(d_A, d_B, d_C, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        cudaEventElapsedTime(&time_v2, start, stop);\n",
        "\n",
        "        printf(\"%-12d %-12.3f %-18.3f %-18.3f\\n\", N, hostTime, time_v1, time_v2);\n",
        "\n",
        "        cudaFree(d_A);\n",
        "        cudaFree(d_B);\n",
        "        cudaFree(d_C);\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS1ZkdS6FiD2",
        "outputId": "fcda06ca-8e8f-4164-e2ac-96ddd5d52cdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing HW0_P2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc HW0_P2.cu -o HW0_P2\n",
        "!./HW0_P2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX0viivtFh7W",
        "outputId": "70711794-a1d7-4164-f1e0-81b8405d7f2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorSize   HostTime(ms) Device_v1(ms)      Device_v2(ms)     \n",
            "64           0.001        43.921             0.003             \n",
            "256          0.002        0.003              0.002             \n",
            "1024         0.005        0.003              0.002             \n",
            "4096         0.018        0.002              0.002             \n",
            "16384        0.066        0.002              0.002             \n",
            "65536        0.251        0.002              0.002             \n",
            "262144       1.537        0.002              0.002             \n",
            "1048576      5.983        0.002              0.002             \n",
            "4194304      24.230       0.003              0.002             \n",
            "16777216     99.628       0.003              0.002             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3oOxexcUFniX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datamining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}